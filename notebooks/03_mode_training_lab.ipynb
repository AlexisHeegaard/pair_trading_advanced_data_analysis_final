{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85b35d36",
   "metadata": {},
   "source": [
    "THIS NOTEBOOK TRAINS THE RIDGe CLASSIFIER AND LSTM MODELS BASED ON PREVIOUSLY CREATED FEATURE\n",
    "it implements the core machine learning pipeline defined in models.py\n",
    "\n",
    "the models takes the following input features:\n",
    "1.Z-Score\n",
    "2.Range_postion\n",
    "3.MR_Strenght\n",
    "\n",
    "and the following target variable:\n",
    "1.target direction: a binary label 1-0\n",
    "\n",
    "the models are trained to capture relationship between input features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed384dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING PHASE\n",
      "================================================================================\n",
      "Training Ridge...\n",
      "Training LSTM...\n",
      "\n",
      " Saving to ../models/ ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import joblib  #\n",
    "import json    \n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Setup paths\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.models import BaselineModel, LSTMModel\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING PHASE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. CONFIGURATION\n",
    "SELECTED_FEATURES = ['Z_Score', 'Range_Position', 'MR_Strength']\n",
    "TRAIN_END = '2023-12-31'\n",
    "LOOKBACK = 10\n",
    "\n",
    "# 2. LOAD DATA\n",
    "df = pd.read_csv('../data/processed/04_ml_ready_features.csv', index_col=0, parse_dates=True)\n",
    "df_train = df[df.index <= TRAIN_END].copy()\n",
    "\n",
    "# 3. PREPARE & SCALE\n",
    "# Important: We fit the scaler ONLY on training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_vals = scaler.fit_transform(df_train[SELECTED_FEATURES])\n",
    "\n",
    "# Helper to rebuild DF for sequencing\n",
    "df_train_proc = pd.DataFrame(X_train_vals, columns=SELECTED_FEATURES, index=df_train.index)\n",
    "df_train_proc['Target'] = df_train['Target_Direction'].values\n",
    "df_train_proc['Pair_ID'] = df_train['Pair_ID'].values\n",
    "df_train_proc['Original_Index'] = np.arange(len(df_train))\n",
    "\n",
    "# 4. GENERATE SEQUENCES\n",
    "def create_pair_sequences(data_df, feature_cols, lookback=10):\n",
    "    X_seq, y_seq = [], []\n",
    "    for pair in data_df['Pair_ID'].unique():\n",
    "        pair_df = data_df[data_df['Pair_ID'] == pair].reset_index(drop=True)\n",
    "        X_vals = pair_df[feature_cols].values\n",
    "        y_vals = pair_df['Target'].values\n",
    "        if len(X_vals) <= lookback: continue\n",
    "        for i in range(len(X_vals) - lookback):\n",
    "            X_seq.append(X_vals[i:i+lookback])\n",
    "            y_seq.append(y_vals[i+lookback])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_train_3d, y_train = create_pair_sequences(df_train_proc, SELECTED_FEATURES, lookback=LOOKBACK)\n",
    "X_train_2d = np.array([s[-1] for s in X_train_3d])\n",
    "\n",
    "# 5. TRAIN MODELS\n",
    "print(\"Training Ridge...\")\n",
    "model_ridge = BaselineModel(alpha=1.0)\n",
    "model_ridge.fit(X_train_2d, y_train)\n",
    "\n",
    "print(\"Training LSTM...\")\n",
    "X_train_t3d = torch.FloatTensor(X_train_3d)\n",
    "y_train_t = torch.FloatTensor(y_train).view(-1, 1)\n",
    "\n",
    "model_lstm = LSTMModel(input_dim=len(SELECTED_FEATURES))\n",
    "optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model_lstm.train()\n",
    "for epoch in range(100): # Fast training loop\n",
    "    optimizer.zero_grad()\n",
    "    output = model_lstm(X_train_t3d)\n",
    "    loss = criterion(output, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "print(f\"\\n Saving to ../models/ ...\")\n",
    "\n",
    "# 1. Save the Models\n",
    "joblib.dump(model_ridge, '../models/ridge_model.pkl')\n",
    "torch.save(model_lstm.state_dict(), '../models/lstm_model.pth')\n",
    "\n",
    "# 2. Save the Scaler (CRITICAL!)\n",
    "# If you don't save this, the prediction notebook won't know how to scale new data\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "\n",
    "# 3. Save Config (So prediction notebook knows what features to use)\n",
    "config = {\n",
    "    \"features\": SELECTED_FEATURES,\n",
    "    \"lookback\": LOOKBACK,\n",
    "    \"train_end_date\": TRAIN_END\n",
    "}\n",
    "with open('../models/config.json', 'w') as f:\n",
    "    json.dump(config, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873c6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27a694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aea491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
