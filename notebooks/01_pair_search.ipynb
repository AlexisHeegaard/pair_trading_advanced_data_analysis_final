{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240c3c77",
   "metadata": {},
   "source": [
    "PAIR DISCOVERY - CLUSTERING AND COINTEGRATION\n",
    "\n",
    "This section identifies tradable pairs within each sector using a two step statistical approach\n",
    "\n",
    "Time period:\n",
    "1.training data only (2021-01-01 to 2023-12-31)\n",
    "2.test period (2024-2024) is reserved for out-of-sample validation\n",
    "\n",
    "processing steps:\n",
    "1.load price and returns data for each sector\n",
    "2.apply time filter to use only training period data\n",
    "3.cluster stocks based on return similarities\n",
    "4.test for cointegration between all stock pairs within each cluster\n",
    "5.collect pairs that pass the cointegration test\n",
    "\n",
    "OUTPUT: \"01_cointegrated_pairs.csv in /data/processed/\n",
    "-stock1, stock2, (the pairs)\n",
    "-cluster ID\n",
    "sector\n",
    "-cointegration test statistics\n",
    "\n",
    "\n",
    "import from src.statitics the following functions:\n",
    "1.get_clusters\n",
    "2.find_cointegrated_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a9183",
   "metadata": {},
   "source": [
    "PCA CONFIGURATION\n",
    "A fixed value of 5 principal components was used across all sectors for consistency.$\n",
    "\n",
    "The following code performs a diagnostic analysis, showing the optimal component vary by sector. While a dynamic approach could improve clustering accuracy, a fixed value was choosen to maintain a uniform methology and prioritize dominant market factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "787bedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communication_services: 7 components needed for 80% variance\n",
      "consumer_discretionary: 12 components needed for 80% variance\n",
      "consumer_staples: 11 components needed for 80% variance\n",
      "energy: 3 components needed for 80% variance\n",
      "financials: 9 components needed for 80% variance\n",
      "health_care: 1 components needed for 80% variance\n",
      "industrials: 1 components needed for 80% variance\n",
      "information_technology: 14 components needed for 80% variance\n",
      "materials: 7 components needed for 80% variance\n",
      "real_estate: 8 components needed for 80% variance\n",
      "utilities: 5 components needed for 80% variance\n"
     ]
    }
   ],
   "source": [
    "# PCA DIAGNOSTIC - All sectors\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "processed_dir = '../data/processed'\n",
    "\n",
    "for filename in os.listdir(processed_dir):\n",
    "    if filename.endswith('_returns.csv'):\n",
    "        sector = filename.replace('_returns.csv', '')\n",
    "        \n",
    "        returns_df = pd.read_csv(os.path.join(processed_dir, filename), \n",
    "                                  index_col=0, parse_dates=True)\n",
    "        \n",
    "        pca = PCA(n_components=min(15, len(returns_df.columns)-1))\n",
    "        pca.fit(returns_df)\n",
    "        \n",
    "        cumvar = pca.explained_variance_ratio_.cumsum()\n",
    "        n_for_80 = (cumvar >= 0.80).argmax() + 1\n",
    "        \n",
    "        print(f\"{sector}: {n_for_80} components needed for 80% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d789b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 1: MINING FOR PAIRS (Clustering and Cointegration)\n",
      "TIME FILTER ACTIVE: Only analyzing data from 2021-01-01 to 2023-12-31\n",
      "(Training period: 2021-2023 | Test period: 2024-2025)\n",
      "\n",
      "\n",
      "--- Sector: COMMUNICATION_SERVICES ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 2 clusters...\n",
      "  > Checking Cluster 0 (3 stocks)...\n",
      "  > Checking Cluster 1 (2 stocks)...\n",
      "   -> Found 2 cointegrated pairs.\n",
      "\n",
      "--- Sector: CONSUMER_DISCRETIONARY ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 8 clusters...\n",
      "  > Checking Cluster 0 (2 stocks)...\n",
      "  > Checking Cluster 1 (8 stocks)...\n",
      "  > Checking Cluster 2 (3 stocks)...\n",
      "  > Checking Cluster 3 (6 stocks)...\n",
      "  > Checking Cluster 4 (2 stocks)...\n",
      "  > Checking Cluster 5 (2 stocks)...\n",
      "  > Checking Cluster 6 (4 stocks)...\n",
      "  > Checking Cluster 7 (3 stocks)...\n",
      "   -> Found 4 cointegrated pairs.\n",
      "\n",
      "--- Sector: CONSUMER_STAPLES ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 3 clusters...\n",
      "  > Checking Cluster 0 (3 stocks)...\n",
      "  > Checking Cluster 1 (6 stocks)...\n",
      "  > Checking Cluster 2 (7 stocks)...\n",
      "   -> Found 9 cointegrated pairs.\n",
      "\n",
      "--- Sector: ENERGY ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 5 clusters...\n",
      "  > Checking Cluster 0 (2 stocks)...\n",
      "  > Checking Cluster 1 (2 stocks)...\n",
      "  > Checking Cluster 2 (2 stocks)...\n",
      "  > Checking Cluster 3 (2 stocks)...\n",
      "  > Checking Cluster 4 (2 stocks)...\n",
      "   -> Found 1 cointegrated pairs.\n",
      "\n",
      "--- Sector: FINANCIALS ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 5 clusters...\n",
      "  > Checking Cluster 0 (13 stocks)...\n",
      "  > Checking Cluster 1 (4 stocks)...\n",
      "  > Checking Cluster 2 (24 stocks)...\n",
      "  > Checking Cluster 3 (5 stocks)...\n",
      "  > Checking Cluster 4 (3 stocks)...\n",
      "   -> Found 38 cointegrated pairs.\n",
      "\n",
      "--- Sector: HEALTH_CARE ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 5 clusters...\n",
      "  > Checking Cluster 0 (7 stocks)...\n",
      "  > Checking Cluster 1 (7 stocks)...\n",
      "  > Checking Cluster 2 (8 stocks)...\n",
      "  > Checking Cluster 3 (2 stocks)...\n",
      "  > Checking Cluster 4 (9 stocks)...\n",
      "   -> Found 12 cointegrated pairs.\n",
      "\n",
      "--- Sector: INDUSTRIALS ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 9 clusters...\n",
      "  > Checking Cluster 0 (5 stocks)...\n",
      "  > Checking Cluster 1 (18 stocks)...\n",
      "  > Checking Cluster 2 (2 stocks)...\n",
      "  > Checking Cluster 3 (6 stocks)...\n",
      "  > Checking Cluster 4 (2 stocks)...\n",
      "  > Checking Cluster 5 (3 stocks)...\n",
      "  > Checking Cluster 6 (2 stocks)...\n",
      "  > Checking Cluster 7 (5 stocks)...\n",
      "  > Checking Cluster 8 (2 stocks)...\n",
      "   -> Found 17 cointegrated pairs.\n",
      "\n",
      "--- Sector: INFORMATION_TECHNOLOGY ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 4 clusters...\n",
      "  > Checking Cluster 0 (13 stocks)...\n",
      "  > Checking Cluster 1 (12 stocks)...\n",
      "  > Checking Cluster 2 (15 stocks)...\n",
      "  > Checking Cluster 3 (2 stocks)...\n",
      "   -> Found 26 cointegrated pairs.\n",
      "\n",
      "--- Sector: MATERIALS ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 5 clusters...\n",
      "  > Checking Cluster 0 (3 stocks)...\n",
      "  > Checking Cluster 1 (2 stocks)...\n",
      "  > Checking Cluster 2 (4 stocks)...\n",
      "  > Checking Cluster 3 (2 stocks)...\n",
      "  > Checking Cluster 4 (2 stocks)...\n",
      "   -> Found 1 cointegrated pairs.\n",
      "\n",
      "--- Sector: REAL_ESTATE ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 5 clusters...\n",
      "  > Checking Cluster 0 (3 stocks)...\n",
      "  > Checking Cluster 1 (2 stocks)...\n",
      "  > Checking Cluster 2 (2 stocks)...\n",
      "  > Checking Cluster 3 (2 stocks)...\n",
      "  > Checking Cluster 4 (2 stocks)...\n",
      "\n",
      "--- Sector: TECH ---\n",
      "   Missing returns file. Skipping.\n",
      "\n",
      "--- Sector: UTILITIES ---\n",
      "   Clustering...\n",
      "   Cointegration Test...\n",
      "Testing Cointegration on 1 clusters...\n",
      "  > Checking Cluster 0 (16 stocks)...\n",
      "   -> Found 18 cointegrated pairs.\n",
      "\n",
      "SUCCESS! Saved checkpoint to: ../data/processed/01_cointegrated_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "#FIND TRADABLE RELATIONSHPS\n",
    "#TRADABLE PAIRS\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Setup paths\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.statistics import get_clusters, find_cointegrated_pairs\n",
    "\n",
    "raw_dir = '../data/raw'\n",
    "processed_dir = '../data/processed'\n",
    "\n",
    "#time filter configuration\n",
    "TRAIN_START_DATE = pd.Timestamp('2021-01-01')\n",
    "TRAIN_END_DATE = pd.Timestamp('2023-12-31')\n",
    "\n",
    "\n",
    "\n",
    "all_valid_pairs = []\n",
    "\n",
    "print(\"PART 1: MINING FOR PAIRS (Clustering and Cointegration)\")\n",
    "print(f\"TIME FILTER ACTIVE: Only analyzing data from {TRAIN_START_DATE.date()} to {TRAIN_END_DATE.date()}\")\n",
    "print(f\"(Training period: 2021-2023 | Test period: 2024-2025)\\n\")\n",
    "\n",
    "\n",
    "for filename in os.listdir(raw_dir):\n",
    "    if filename.endswith(\"_prices.csv\"):\n",
    "        sector_name = filename.replace(\"_prices.csv\", \"\")\n",
    "        print(f\"\\n--- Sector: {sector_name.upper()} ---\")\n",
    "\n",
    "        # Load Data\n",
    "        try:\n",
    "            price_path = os.path.join(raw_dir, filename)\n",
    "            returns_path = os.path.join(processed_dir, f\"{sector_name}_returns.csv\")\n",
    "            \n",
    "            if not os.path.exists(returns_path):\n",
    "                print(\"   Missing returns file. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            prices = pd.read_csv(price_path, index_col=0, parse_dates=True)\n",
    "            returns = pd.read_csv(returns_path, index_col=0, parse_dates=True)\n",
    "        except Exception as e:\n",
    "            print(f\"   Load Error: {e}\")\n",
    "            continue\n",
    "\n",
    "#apply time filter\n",
    "        prices = prices.loc[TRAIN_START_DATE:TRAIN_END_DATE]\n",
    "        returns = returns.loc[TRAIN_START_DATE:TRAIN_END_DATE]\n",
    "\n",
    "        # Step 1: Cluster\n",
    "        print(\"   Clustering...\")\n",
    "        found_clusters = get_clusters(returns, eps=0.35)\n",
    "        if found_clusters.empty: continue\n",
    "\n",
    "        # Step 2: Cointegration\n",
    "        print(\"   Cointegration Test...\")\n",
    "        sector_pairs = find_cointegrated_pairs(prices, found_clusters)\n",
    "\n",
    "        if not sector_pairs.empty:\n",
    "            # Clean up names\n",
    "            sector_pairs = sector_pairs.rename(columns={'Stock A': 'Stock1', 'Stock B': 'Stock2'})\n",
    "            sector_pairs['Cluster'] = sector_name + \"_\" + sector_pairs['Cluster'].astype(str)\n",
    "            sector_pairs['Sector'] = sector_name\n",
    "            \n",
    "            all_valid_pairs.append(sector_pairs)\n",
    "            print(f\"   -> Found {len(sector_pairs)} cointegrated pairs.\")\n",
    "\n",
    "# SAVE CHECKPOINT\n",
    "if all_valid_pairs:\n",
    "    master_list = pd.concat(all_valid_pairs, ignore_index=True)\n",
    "    output_path = '../data/processed/01_cointegrated_pairs.csv'\n",
    "    master_list.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSUCCESS! Saved checkpoint to: {output_path}\")\n",
    "else:\n",
    "    print(\"\\nNo pairs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa48ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfebd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table successfully saved to: ../results\\final_tradable_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "#save the cointegrated pairs table to outputs folder as well\n",
    "import os\n",
    "\n",
    "# 1. Define the paths\n",
    "source_path = '../data/processed/02_final_tradable_pairs.csv'\n",
    "output_dir = '../results'\n",
    "output_path = os.path.join(output_dir, 'final_tradable_pairs.csv')\n",
    "\n",
    "# 2. Load the CSV \n",
    "df_final = pd.read_csv(source_path)\n",
    "\n",
    "# 4. Save the table to the output folder\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Table successfully saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e0bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['communication_services' 'consumer_discretionary' 'consumer_staples'\n",
      " 'energy' 'financials' 'health_care' 'industrials'\n",
      " 'information_technology' 'materials' 'utilities']\n"
     ]
    }
   ],
   "source": [
    "#check if all GICS sectors were processed, or if not which sector were processed\n",
    "master_list = pd.read_csv('../data/processed/01_cointegrated_pairs.csv')\n",
    "print(master_list['Sector'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
